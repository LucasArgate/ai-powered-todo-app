# RAG (Retrieval-Augmented Generation) üß†

Um guia completo para implementar sistemas RAG robustos com persist√™ncia, usando LlamaIndex e ChromaDB para extra√ß√£o de dados estruturados de documentos.

- **[üöÄ Exemplo Pr√°tico RAG](./apps/ia/examples/rag-chroma/)** - Implementa√ß√£o funcional com LlamaIndex e ChromaDB

## üéØ O que √© RAG?

**RAG (Retrieval-Augmented Generation)** √© uma arquitetura que combina:
- **Retrieval**: Busca de informa√ß√µes relevantes em uma base de conhecimento
- **Augmented**: Enriquecimento do contexto com dados recuperados
- **Generation**: Gera√ß√£o de respostas usando modelos de linguagem

Esta abordagem permite que LLMs acessem informa√ß√µes espec√≠ficas e atualizadas sem precisar ser retreinados.

## üèóÔ∏è Arquitetura RAG com Persist√™ncia

### Componentes Principais

1. **üìÑ Documentos**: PDFs, textos, dados estruturados
2. **üîç Vector Store**: ChromaDB para armazenamento persistente de embeddings
3. **üß† LLM**: Modelo de linguagem para processamento e gera√ß√£o
4. **‚öôÔ∏è Orquestrador**: LlamaIndex para coordena√ß√£o do processo

### Fluxo de Funcionamento

```mermaid
graph TD
    A[Documentos PDF] --> B[LlamaIndex Reader]
    B --> C[Text Chunking]
    C --> D[Embedding Generation]
    D --> E[ChromaDB Storage]
    E --> F[Query Processing]
    F --> G[Vector Search]
    G --> H[Context Retrieval]
    H --> I[LLM Processing]
    I --> J[Structured Output]
```

## üöÄ Implementa√ß√£o Pr√°tica

### Passo 0: Instala√ß√£o das Depend√™ncias

```bash
pip install llama-index llama-index-vector-stores-chroma llama-index-llms-openai chromadb reportlab pydantic
```

**Configura√ß√£o da API Key:**
```bash
export OPENAI_API_KEY="sua_chave_aqui"
```

### Passo 1: C√≥digo Completo

```python
import os
from reportlab.pdfgen import canvas
from reportlab.lib.pagesizes import letter
from typing import List, Optional

# --- LlamaIndex & ChromaDB Imports ---
from llama_index.core import VectorStoreIndex, SimpleDirectoryReader, StorageContext
from llama_index.vector_stores.chroma import ChromaVectorStore
from llama_index.llms.openai import OpenAI
import chromadb

# --- Pydantic para Sa√≠da Estruturada ---
from pydantic import BaseModel, Field

# ==============================================================================
# 1. FUN√á√ïES AUXILIARES PARA CRIAR PDFs DE EXEMPLO
# ==============================================================================
def setup_documentos(diretorio="documentos_pdf"):
    """Cria um diret√≥rio e alguns PDFs de exemplo dentro dele."""
    os.makedirs(diretorio, exist_ok=True)
    
    # PDF 1: Fatura
    caminho_fatura = os.path.join(diretorio, "fatura_001.pdf")
    if not os.path.exists(caminho_fatura):
        print(f"Criando PDF: {caminho_fatura}")
        c = canvas.Canvas(caminho_fatura, pagesize=letter)
        c.drawString(72, 800, "Fatura N¬∫: 2025-001")
        c.drawString(72, 780, "Cliente: Corpora√ß√£o Acme")
        c.drawString(72, 760, "Item: Servi√ßo de Consultoria de Agentes IA")
        c.drawString(72, 740, "Valor Total: R$ 7500.00")
        c.save()

    # PDF 2: Proposta de Projeto
    caminho_proposta = os.path.join(diretorio, "proposta_phoenix.pdf")
    if not os.path.exists(caminho_proposta):
        print(f"Criando PDF: {caminho_proposta}")
        c = canvas.Canvas(caminho_proposta, pagesize=letter)
        c.drawString(72, 800, "Proposta de Projeto: Phoenix")
        c.drawString(72, 780, "Cliente: Stark Industries")
        c.drawString(72, 760, "Descri√ß√£o: Desenvolvimento de um novo sistema de energia.")
        c.drawString(72, 740, "Valor Total: R$ 1,200,000.00")
        c.save()

# ==============================================================================
# 2. DEFINIR O SCHEMA DE SA√çDA ESTRUTURADA (JSON)
# ==============================================================================
class EntidadeExtraida(BaseModel):
    """Modelo para os dados que queremos extrair dos documentos."""
    nome_cliente: Optional[str] = Field(description="O nome do cliente associado ao documento.")
    nome_projeto: Optional[str] = Field(description="O nome do projeto, se mencionado.")
    valor_total: Optional[float] = Field(description="O valor financeiro total encontrado no documento.")

# ==============================================================================
# 3. L√ìGICA PRINCIPAL: INDEXAR, PERSISTIR E CONSULTAR
# ==============================================================================
def main():
    # --- Configura√ß√µes ---
    PDF_DIRECTORY = "./documentos_pdf"
    DB_PATH = "./chroma_db"
    COLLECTION_NAME = "documentos_collection"

    # Passo 1: Criar os documentos de exemplo
    setup_documentos(PDF_DIRECTORY)

    # Passo 2: Inicializar o cliente ChromaDB persistente
    # Ele criar√° o diret√≥rio DB_PATH se n√£o existir
    db = chromadb.PersistentClient(path=DB_PATH)
    
    # Passo 3: Obter ou criar a cole√ß√£o no ChromaDB
    # Esta √© a chave para a persist√™ncia!
    chroma_collection = db.get_or_create_collection(COLLECTION_NAME)

    # Passo 4: Criar o LlamaIndex VectorStore em cima da cole√ß√£o do Chroma
    vector_store = ChromaVectorStore(chroma_collection=chroma_collection)
    
    # --- L√≥gica de "Save" vs "Load" ---
    # Verificamos se a cole√ß√£o j√° tem documentos.
    # Se count() for 0, √© a primeira vez, ent√£o precisamos indexar.
    if chroma_collection.count() == 0:
        print("Cole√ß√£o vazia. Indexando novos documentos...")
        
        # Carregar documentos do diret√≥rio
        documents = SimpleDirectoryReader(PDF_DIRECTORY).load_data()
        
        # Criar o StorageContext e o Index
        storage_context = StorageContext.from_defaults(vector_store=vector_store)
        index = VectorStoreIndex.from_documents(
            documents, storage_context=storage_context
        )
        print(f"Indexa√ß√£o conclu√≠da. {len(documents)} documentos adicionados √† cole√ß√£o '{COLLECTION_NAME}'.")
    else:
        print(f"Carregando √≠ndice a partir do ChromaDB existente na cole√ß√£o '{COLLECTION_NAME}'...")
        # Se a cole√ß√£o j√° tem dados, LlamaIndex pode us√°-la diretamente
        index = VectorStoreIndex.from_vector_store(
            vector_store=vector_store,
        )
        print("√çndice carregado com sucesso.")

    # Passo 5: Criar o Query Engine para extrair dados estruturados
    query_engine = index.as_query_engine(
        output_cls=EntidadeExtraida,
        llm=OpenAI(model="gpt-4-turbo"), # Modelos fortes s√£o melhores para extra√ß√£o
    )

    # Passo 6: Fazer a consulta
    # A query √© projetada para for√ßar o RAG a olhar os dois documentos
    query_str = "Qual o valor total da proposta para a Stark Industries e quem √© o cliente da fatura 2025-001?"
    
    print("\n--- Executando Consulta ---")
    print(f"Query: {query_str}")
    
    response = query_engine.query(query_str)
    
    # O resultado j√° √© um objeto Pydantic
    dados_extraidos = response.response
    
    print("\n--- Dados Estruturados Extra√≠dos (JSON) ---")
    print(dados_extraidos.model_dump_json(indent=2))


if __name__ == "__main__":
    main()
```

## üîÑ Persist√™ncia e Otimiza√ß√£o

### Primeira Execu√ß√£o
```bash
python rag_com_chroma.py
```

**Sa√≠da esperada:**
```
Criando PDF: documentos_pdf/fatura_001.pdf
Criando PDF: documentos_pdf/proposta_phoenix.pdf
Cole√ß√£o vazia. Indexando novos documentos...
[...logs de processamento...]
Indexa√ß√£o conclu√≠da. 2 documentos adicionados √† cole√ß√£o 'documentos_collection'.

--- Executando Consulta ---
Query: Qual o valor total da proposta para a Stark Industries e quem √© o cliente da fatura 2025-001?

--- Dados Estruturados Extra√≠dos (JSON) ---
{
  "nome_cliente": "Corpora√ß√£o Acme",
  "nome_projeto": "Phoenix",
  "valor_total": 1200000.0
}
```

### Segunda Execu√ß√£o (Persist√™ncia)
```bash
python rag_com_chroma.py
```

**Sa√≠da esperada:**
```
Carregando √≠ndice a partir do ChromaDB existente na cole√ß√£o 'documentos_collection'...
√çndice carregado com sucesso.

--- Executando Consulta ---
Query: Qual o valor total da proposta para a Stark Industries e quem √© o cliente da fatura 2025-001?

--- Dados Estruturados Extra√≠dos (JSON) ---
{
  "nome_cliente": "Corpora√ß√£o Acme",
  "nome_projeto": "Phoenix",
  "valor_total": 1200000.0
}
```

**‚ö° Performance**: A segunda execu√ß√£o √© significativamente mais r√°pida, pois os embeddings j√° est√£o armazenados no ChromaDB.

## üéØ Casos de Uso

### 1. Extra√ß√£o de Dados Financeiros
- **Input**: Faturas, propostas, contratos
- **Output**: Valores, clientes, datas em formato JSON estruturado
- **Aplica√ß√£o**: Automa√ß√£o de processos cont√°beis

### 2. An√°lise de Documentos Legais
- **Input**: Contratos, termos de servi√ßo, pol√≠ticas
- **Output**: Cl√°usulas espec√≠ficas, obriga√ß√µes, prazos
- **Aplica√ß√£o**: Compliance e an√°lise de risco

### 3. Processamento de Relat√≥rios
- **Input**: Relat√≥rios t√©cnicos, an√°lises de mercado
- **Output**: M√©tricas, tend√™ncias, insights
- **Aplica√ß√£o**: Business intelligence automatizado

### 4. Gest√£o de Conhecimento
- **Input**: Manuais, documenta√ß√£o t√©cnica, FAQs
- **Output**: Respostas contextuais e precisas
- **Aplica√ß√£o**: Sistemas de suporte e helpdesk

## üõ†Ô∏è Configura√ß√µes Avan√ßadas

### Modelos de Embedding
```python
# Usar diferentes modelos de embedding
from llama_index.embeddings.openai import OpenAIEmbedding

embed_model = OpenAIEmbedding(
    model="text-embedding-3-large",
    dimensions=3072  # Dimens√µes customizadas
)
```

### Chunking Estrat√©gico
```python
from llama_index.core.node_parser import SentenceSplitter

# Configurar tamanho e sobreposi√ß√£o dos chunks
node_parser = SentenceSplitter(
    chunk_size=1024,
    chunk_overlap=200
)
```

### Filtros e Metadados
```python
# Adicionar metadados aos documentos
documents = SimpleDirectoryReader(PDF_DIRECTORY).load_data()
for doc in documents:
    doc.metadata = {
        "source": doc.metadata.get("file_path", ""),
        "type": "financial_document",
        "processed_at": datetime.now().isoformat()
    }
```

## üìä M√©tricas e Monitoramento

### Performance
- **Tempo de Indexa√ß√£o**: Medir velocidade de processamento inicial
- **Tempo de Query**: Monitorar lat√™ncia das consultas
- **Precis√£o**: Avaliar qualidade das extra√ß√µes

### Qualidade
- **Relev√¢ncia**: Verificar se os chunks recuperados s√£o relevantes
- **Completude**: Garantir que todas as informa√ß√µes necess√°rias s√£o extra√≠das
- **Consist√™ncia**: Manter qualidade uniforme entre diferentes documentos

## üîß Troubleshooting

### Problemas Comuns

1. **Erro de API Key**
   ```bash
   # Verificar se a vari√°vel est√° configurada
   echo $OPENAI_API_KEY
   ```

2. **Mem√≥ria Insuficiente**
   ```python
   # Reduzir tamanho dos chunks
   node_parser = SentenceSplitter(chunk_size=512)
   ```

3. **Qualidade Baixa das Extra√ß√µes**
   ```python
   # Usar modelo mais poderoso
   llm=OpenAI(model="gpt-4-turbo")
   ```

### Otimiza√ß√µes

1. **Cache de Embeddings**: Reutilizar embeddings para documentos similares
2. **Indexa√ß√£o Incremental**: Adicionar apenas novos documentos
3. **Compress√£o**: Usar modelos de embedding com menos dimens√µes
4. **Filtros**: Implementar filtros por metadados para consultas mais precisas

## üöÄ Pr√≥ximos Passos

- [ ] Integra√ß√£o com banco de dados para metadados
- [ ] Interface web para upload de documentos
- [ ] Sistema de versionamento de documentos
- [ ] An√°lise de sentimento e classifica√ß√£o autom√°tica
- [ ] Integra√ß√£o com APIs externas para enriquecimento
- [ ] Sistema de feedback para melhoria cont√≠nua

## üìö Refer√™ncias

- [LlamaIndex Documentation](https://docs.llamaindex.ai/)
- [ChromaDB Documentation](https://docs.trychroma.com/)
- [OpenAI API Reference](https://platform.openai.com/docs)
- [Pydantic Documentation](https://docs.pydantic.dev/)

## ü§ù Contribuindo

Para contribuir com melhorias no sistema RAG:

1. **Testes**: Adicione casos de teste para novos tipos de documentos
2. **Performance**: Otimize algoritmos de chunking e embedding
3. **Documenta√ß√£o**: Melhore exemplos e casos de uso
4. **Integra√ß√£o**: Adicione suporte para novos formatos de arquivo
5. **Monitoramento**: Implemente m√©tricas de qualidade e performance

---

**üí° Dica**: Este sistema RAG pode ser facilmente integrado com agentes LangGraph para criar workflows mais complexos e inteligentes, seguindo os princ√≠pios estrat√©gicos definidos na documenta√ß√£o do projeto.
